{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk1VMcAR3N4y",
        "outputId": "49586bf7-72ab-4e0c-8d8b-74b545c57799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ct_DVnR3gXs",
        "outputId": "e7cf08b2-6f4d-4a90-a69e-6222983b64d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.environ['OPENAI_API_KEY']='put your key'"
      ],
      "metadata": {
        "id": "nfKw0mSg348P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "ALXfR7d_8tXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.5)"
      ],
      "metadata": {
        "id": "wmhC5sdL86Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what are some hill station for someone who likes peak view?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgJt2nHP9DY5",
        "outputId": "4b1d218f-05d9-4c8c-dd23-90a2a2d42d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Shimla, India\n",
            "2. Manali, India\n",
            "3. Gulmarg, India\n",
            "4. Mount Abu, India\n",
            "5. Darjeeling, India\n",
            "6. Nainital, India\n",
            "7. Ooty, India\n",
            "8. Mussoorie, India\n",
            "9. Kodaikanal, India\n",
            "10. Gangtok, India\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "HmkLBzuR9ZPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=['food'],template=\"What are 5 vacation destinations for someone who likes to eat {food}?\")"
      ],
      "metadata": {
        "id": "IbxevfcA8Ql9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(food = \"sweets\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc6CokiL-Y-1",
        "outputId": "ebf77925-dd0b-46dc-d9ea-0cd6d22000fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are 5 vacation destinations for someone who likes to eat sweets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import prompts\n",
        "print(llm(prompt.format(food='sweets')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjp0XcOR_HIW",
        "outputId": "b9cd91c3-4152-4817-c208-d7373e5aa6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Tokyo, Japan - known for its unique and delicious desserts, from traditional mochi to modern-day creations like the rainbow-colored cotton candy.\n",
            "\n",
            "2. Paris, France - the city of love is also home to some of the world's most delicious pastries, from the classic macarons to the decadent éclairs.\n",
            "\n",
            "3. New York City, USA - the city that never sleeps is also home to some of the most delicious desserts in the world, from classic cheesecake to the more modern Cronut.\n",
            "\n",
            "4. Rome, Italy - the city of romance is also home to some of the world's most delicious gelato, from the classic stracciatella to the more exotic flavors like pistachio.\n",
            "\n",
            "5. London, England - the city of royalty is also home to some of the world's most iconic desserts, from traditional sticky toffee pudding to the more modern Eton Mess.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -q"
      ],
      "metadata": {
        "id": "__80maOF_Z6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cbf84c-8fd0-422b-8b43-d29802c6de80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "2qu84cClHDqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "hwLPPMJrgvIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"SERPAPI_API_KEY\"] = \"put your key\""
      ],
      "metadata": {
        "id": "yJfRsG7khk-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools( ['serpapi', 'llm-math'],llm=llm)"
      ],
      "metadata": {
        "id": "1_yq1Cvcg4dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "irSece6uhu5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's test it out!\n",
        "agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "rUNfgdjTiTDC",
        "outputId": "07b74e1e-c0e9-4b9c-9046-23bc232275b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to find out who the leader of Japan is and then calculate the largest prime number that is smaller than their age.\n",
            "Action: Search\n",
            "Action Input: \"current leader of Japan\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mFumio Kishida\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out the age of the leader of Japan\n",
            "Action: Search\n",
            "Action Input: \"age of Fumio Kishida\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m65 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the largest prime number that is smaller than 65\n",
            "Action: Calculator\n",
            "Action Input: 65\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 65\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"who is the tallest guy in India? how we can connect with any cricketer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "5vs2Xs__iWE6",
        "outputId": "533c9568-5701-46e3-c28c-7ada5b0c1511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to find out who the tallest guy in India is and how to connect with a cricketer\n",
            "Action: Search\n",
            "Action Input: \"tallest guy in India\" \"connect with cricketer\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAbey Kuruvilla: Generally regarded as the tallest man to play for India, Abey Kuruvilla stands at an imposing 6'6” and had the potential to be a very handy ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out how to connect with a cricketer\n",
            "Action: Search\n",
            "Action Input: \"connect with cricketer\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSummertime Smiles: Feeding families together. Cricket is helping families in need of food assistance. In the Community. Cricket Helps Provide Meals to Families ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The tallest guy in India is Abey Kuruvilla and you can connect with a cricketer by participating in community initiatives such as Cricket Helps Provide Meals to Families.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The tallest guy in India is Abey Kuruvilla and you can connect with a cricketer by participating in community initiatives such as Cricket Helps Provide Meals to Families.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain"
      ],
      "metadata": {
        "id": "yzkOjvgRyHUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "yTIxiTl-32Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "ZgSRP_8FBPLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I am xyz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "aqo4NdcF36Wf",
        "outputId": "4ee5fc23-58d3-4312-d825-7f15c0a43285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: I am xyz\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what was the our previous conversation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "1XLBm1WCBLdS",
        "outputId": "d3997fd3-ca77-41b4-ef47-9951b31fb289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(8):\n",
        "  a = conversation.predict(input=str(input()))\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilIQmiVVCmHY",
        "outputId": "6157a77d-e63f-4dbe-f06f-a89190123f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  Hi there! How can I help you today?\n",
            "give me temperature of NY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "  The current temperature in New York City is 15 degrees Celsius.\n",
            "who won the ODI series in 2006 between Ind and austraila\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   The 2006 ODI series between India and Australia was won by Australia.\n",
            "what is chemical formula for sulphuric acid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:    The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: what is chemical formula for sulphuric acid\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   The chemical formula for sulphuric acid is H2SO4.\n",
            "but i think india has won in 2006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:    The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: what is chemical formula for sulphuric acid\n",
            "AI:    The chemical formula for sulphuric acid is H2SO4.\n",
            "Human: but i think india has won in 2006\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "   I'm sorry, I don't have the information you are looking for.\n",
            "which you told earlier ind vs austraila, i am talking about that\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:    The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: what is chemical formula for sulphuric acid\n",
            "AI:    The chemical formula for sulphuric acid is H2SO4.\n",
            "Human: but i think india has won in 2006\n",
            "AI:    I'm sorry, I don't have the information you are looking for.\n",
            "Human: which you told earlier ind vs austraila, i am talking about that\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "    I apologize, I don't have the information you are looking for. The 2006 ODI series between India and Australia was won by Australia.\n",
            "which learning technique you are using: zero shot learning or few shot learning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:    The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: what is chemical formula for sulphuric acid\n",
            "AI:    The chemical formula for sulphuric acid is H2SO4.\n",
            "Human: but i think india has won in 2006\n",
            "AI:    I'm sorry, I don't have the information you are looking for.\n",
            "Human: which you told earlier ind vs austraila, i am talking about that\n",
            "AI:     I apologize, I don't have the information you are looking for. The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: which learning technique you are using: zero shot learning or few shot learning\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "    I am using a combination of both zero-shot learning and few-shot learning. Zero-shot learning is a technique that allows a machine learning model to make predictions without any prior training data, while few-shot learning is a technique that allows a machine learning model to make predictions with a small amount of training data.\n",
            "which parameter i should use, so that you will give me all the answers related to few shot learning only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am xyz\n",
            "AI:  Hi xyz, my name is AI. It's nice to meet you. What can I do for you today?\n",
            "Human: what was the our previous conversation\n",
            "AI:  Our previous conversation was about the weather. We talked about how the weather has been changing lately and how it affects our daily lives.\n",
            "Human: hi\n",
            "AI:  Hi there! How can I help you today?\n",
            "Human: you are wrong\n",
            "AI:  I'm sorry, I don't understand what you mean. Could you please explain further?\n",
            "Human: what is your full name?\n",
            "AI:   My full name is AI. It's nice to meet you.\n",
            "Human: okay, what is the latest technology in NLP?\n",
            "AI:  The latest technology in Natural Language Processing (NLP) is called transformers. Transformers are a type of deep learning model that can process large amounts of text data and generate meaningful insights. They are used in many applications such as machine translation, text summarization, and question answering.\n",
            "Human: temprature in bengaluru\n",
            "AI:   The current temperature in Bengaluru is 28 degrees Celsius.\n",
            "Human: hi\n",
            "AI:   Hi there! How can I help you today?\n",
            "Human: give me temperature of NY\n",
            "AI:   The current temperature in New York City is 15 degrees Celsius.\n",
            "Human: who won the ODI series in 2006 between Ind and austraila\n",
            "AI:    The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: what is chemical formula for sulphuric acid\n",
            "AI:    The chemical formula for sulphuric acid is H2SO4.\n",
            "Human: but i think india has won in 2006\n",
            "AI:    I'm sorry, I don't have the information you are looking for.\n",
            "Human: which you told earlier ind vs austraila, i am talking about that\n",
            "AI:     I apologize, I don't have the information you are looking for. The 2006 ODI series between India and Australia was won by Australia.\n",
            "Human: which learning technique you are using: zero shot learning or few shot learning\n",
            "AI:     I am using a combination of both zero-shot learning and few-shot learning. Zero-shot learning is a technique that allows a machine learning model to make predictions without any prior training data, while few-shot learning is a technique that allows a machine learning model to make predictions with a small amount of training data.\n",
            "Human: which parameter i should use, so that you will give me all the answers related to few shot learning only\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "    I'm sorry, I don't know the answer to that question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhuwRBGMDB3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}