{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk1VMcAR3N4y",
        "outputId": "49586bf7-72ab-4e0c-8d8b-74b545c57799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ct_DVnR3gXs",
        "outputId": "e7cf08b2-6f4d-4a90-a69e-6222983b64d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.environ['OPENAI_API_KEY']='put your API_KEY'"
      ],
      "metadata": {
        "id": "nfKw0mSg348P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "ALXfR7d_8tXq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.5)"
      ],
      "metadata": {
        "id": "wmhC5sdL86Po"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what are some hill station for someone who likes peak view?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgJt2nHP9DY5",
        "outputId": "4b1d218f-05d9-4c8c-dd23-90a2a2d42d73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Shimla, India\n",
            "2. Manali, India\n",
            "3. Gulmarg, India\n",
            "4. Mount Abu, India\n",
            "5. Darjeeling, India\n",
            "6. Nainital, India\n",
            "7. Ooty, India\n",
            "8. Mussoorie, India\n",
            "9. Kodaikanal, India\n",
            "10. Gangtok, India\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "HmkLBzuR9ZPx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=['food'],template=\"What are 5 vacation destinations for someone who likes to eat {food}?\")"
      ],
      "metadata": {
        "id": "IbxevfcA8Ql9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(food = \"sweets\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc6CokiL-Y-1",
        "outputId": "ebf77925-dd0b-46dc-d9ea-0cd6d22000fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are 5 vacation destinations for someone who likes to eat sweets?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import prompts\n",
        "print(llm(prompt.format(food='sweets')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjp0XcOR_HIW",
        "outputId": "b9cd91c3-4152-4817-c208-d7373e5aa6de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Tokyo, Japan - known for its unique and delicious desserts, from traditional mochi to modern-day creations like the rainbow-colored cotton candy.\n",
            "\n",
            "2. Paris, France - the city of love is also home to some of the world's most delicious pastries, from the classic macarons to the decadent éclairs.\n",
            "\n",
            "3. New York City, USA - the city that never sleeps is also home to some of the most delicious desserts in the world, from classic cheesecake to the more modern Cronut.\n",
            "\n",
            "4. Rome, Italy - the city of romance is also home to some of the world's most delicious gelato, from the classic stracciatella to the more exotic flavors like pistachio.\n",
            "\n",
            "5. London, England - the city of royalty is also home to some of the world's most iconic desserts, from traditional sticky toffee pudding to the more modern Eton Mess.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -q"
      ],
      "metadata": {
        "id": "__80maOF_Z6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cbf84c-8fd0-422b-8b43-d29802c6de80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "2qu84cClHDqP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "hwLPPMJrgvIb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"SERPAPI_API_KEY\"] = \"put your API_KEY\""
      ],
      "metadata": {
        "id": "yJfRsG7khk-D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools( ['serpapi', 'llm-math'],llm=llm)"
      ],
      "metadata": {
        "id": "1_yq1Cvcg4dy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "irSece6uhu5C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's test it out!\n",
        "agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "rUNfgdjTiTDC",
        "outputId": "07b74e1e-c0e9-4b9c-9046-23bc232275b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to find out who the leader of Japan is and then calculate the largest prime number that is smaller than their age.\n",
            "Action: Search\n",
            "Action Input: \"current leader of Japan\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mFumio Kishida\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out the age of the leader of Japan\n",
            "Action: Search\n",
            "Action Input: \"age of Fumio Kishida\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m65 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the largest prime number that is smaller than 65\n",
            "Action: Calculator\n",
            "Action Input: 65\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 65\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 61.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"who is the tallest guy in India? how we can connect with any cricketer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "5vs2Xs__iWE6",
        "outputId": "533c9568-5701-46e3-c28c-7ada5b0c1511"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to find out who the tallest guy in India is and how to connect with a cricketer\n",
            "Action: Search\n",
            "Action Input: \"tallest guy in India\" \"connect with cricketer\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAbey Kuruvilla: Generally regarded as the tallest man to play for India, Abey Kuruvilla stands at an imposing 6'6” and had the potential to be a very handy ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out how to connect with a cricketer\n",
            "Action: Search\n",
            "Action Input: \"connect with cricketer\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSummertime Smiles: Feeding families together. Cricket is helping families in need of food assistance. In the Community. Cricket Helps Provide Meals to Families ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The tallest guy in India is Abey Kuruvilla and you can connect with a cricketer by participating in community initiatives such as Cricket Helps Provide Meals to Families.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The tallest guy in India is Abey Kuruvilla and you can connect with a cricketer by participating in community initiatives such as Cricket Helps Provide Meals to Families.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzkOjvgRyHUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}